{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89b8c3aa-13f1-4a96-a52e-96ec9ad4d436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights from input to hidden layer after learning:\n",
      "[[  0.14756766  -5.59499672  -0.86073417  -0.77983548  -1.69765732\n",
      "    7.54274719  -3.09541265  -5.9044834   -0.67454445   0.91100537\n",
      "    0.2039275 ]\n",
      " [  2.34185318  -2.34385015  -1.3382283   -6.46947181   0.80696799\n",
      "    3.30533009  -0.67351992  -0.95856234  -1.06321611  -9.04593544\n",
      "    3.9158399 ]\n",
      " [  1.19168517  -6.74847627   0.88464317   4.5995273   -8.54098535\n",
      "    1.67759371   3.7913713    0.09336507  -6.62286961   1.38720554\n",
      "   -0.57282354]\n",
      " [ -1.20743473  -3.97115963   4.53254732   4.23396966  -4.06724144\n",
      "   -3.51313118  12.52906367  -0.26083034   0.08734824  -3.52993768\n",
      "   -5.99992763]\n",
      " [  3.95973717   4.63737502  -0.24584693   2.43065177  -0.18096598\n",
      "   -6.73694773  -6.58464137  -1.87661157   1.55208557  -0.99527257\n",
      "   -1.27369051]\n",
      " [  1.40067351  -1.84203247  -6.61811787   0.69132041  -1.86335703\n",
      "   -3.59194035   9.29235109   1.82293935  -1.63471924  -5.76110676\n",
      "   -0.62215271]\n",
      " [ -0.38123189  -1.21805534  -1.65294841  -5.24489897   4.19048142\n",
      "   -0.71157755  -5.16355407  -0.71425208  11.76341798  -8.13676563\n",
      "   -2.17055657]\n",
      " [  9.02367682  -3.5305027   -7.08217293   5.5406232   -1.13948871\n",
      "    2.25742643   3.39104977   2.09274555  -2.87631164  -1.84981786\n",
      "   -7.23101641]\n",
      " [ -4.15570995   6.68532778  -0.33170814  -1.50270107  -2.96274263\n",
      "  -10.9821501    1.46998866   1.31000996  -1.60633762  -1.98198411\n",
      "    1.49508526]\n",
      " [  3.00789233  -5.50393417  -5.60995603   1.2006527   -1.57395471\n",
      "    0.50125325   8.48359133  -4.6540465    0.93275238  -3.32475781\n",
      "    0.09500876]\n",
      " [ -0.8815251   -4.16917152   4.27533822   1.55369462  -6.04100025\n",
      "   -4.41139814   2.52387532  -3.99394142  -3.39035561  -1.96705944\n",
      "    3.02302551]\n",
      " [  0.6581502    1.67628757  -9.00177706  -2.69077204   8.52936041\n",
      "   -0.36192539  -0.79391118  -4.50181287   0.16516942  -1.42655762\n",
      "   -2.81886475]\n",
      " [  6.52216969   3.83983616  -1.7074291   -1.2243944    3.42980853\n",
      "   -1.25045808  -6.0109424    5.12178449  -3.15222392  -6.06308056\n",
      "   -0.39135215]\n",
      " [  3.62690725  -6.24543558   7.60561918  -3.33358871  -3.20418539\n",
      "    2.50048829  -0.43786086  -0.87134979   1.07676423  -0.15850069\n",
      "   -3.16751654]\n",
      " [ -1.66462183  -4.24871736   7.8769719   -5.03363048  -2.21337365\n",
      "   -4.63075169   1.20180245  -2.56088945   1.81919132  -3.41043536\n",
      "    5.65947709]]\n",
      "\n",
      "Weights from hidden to output layer after learning:\n",
      "[[ 1.59528366e+00 -2.33033472e+00  2.61870266e-01  3.40410662e-01\n",
      "   1.26369418e+00  4.06666764e+00  7.22663449e-01 -2.83971551e+00\n",
      "  -2.75184165e+00 -3.16606783e-01  2.97864927e-02  4.48017721e-01\n",
      "   1.93241306e+00  2.04115121e+00 -3.76392932e-01 -1.15867527e+00]\n",
      " [-1.65562921e+00 -1.41993775e+00  7.22568111e-02  8.23183920e-02\n",
      "  -1.39998504e+00  2.03556734e-01  1.44032252e+00  2.27740984e-01\n",
      "   2.23017953e+00 -1.22479242e+00 -2.18654452e+00  3.84857026e+00\n",
      "  -3.15775150e-01  2.12082141e+00 -5.27167064e-01  2.91978603e-01]\n",
      " [ 2.10101480e-01 -1.07141134e+00  5.97912105e-01  2.45570404e-03\n",
      "   8.95620067e-03 -9.42122511e-01  1.15148443e+00 -1.71511856e+00\n",
      "   1.35207352e+00  1.71802736e+00  1.02277602e+00 -1.15245692e+00\n",
      "   1.90039738e+00  3.21251315e-01 -1.22365221e+00 -4.84696016e-01]\n",
      " [-4.17775790e-01 -1.75207188e+00  8.57081657e-01 -8.18393736e-01\n",
      "  -8.73744757e-01 -2.51241192e-01  1.50843012e+00 -1.89747204e+00\n",
      "   1.79541562e+00  2.11362959e+00  1.82468126e+00 -1.25116871e+00\n",
      "   1.60775141e+00  8.00413937e-01 -2.37179946e+00 -9.38829164e-02]\n",
      " [ 1.51432379e-01  2.22319389e+00 -2.09449807e+00 -1.44324409e+00\n",
      "   1.30872658e+00  9.78966431e-01 -1.21104303e+00 -1.33521999e+00\n",
      "   1.34114340e+00  1.81721608e+00  1.47562253e+00 -3.57101972e+00\n",
      "  -3.66272251e-01  1.33022849e+00 -2.32271192e+00  6.14107058e-01]\n",
      " [-1.41431207e+00 -1.74076091e+00  4.49384529e-01 -2.53725355e+00\n",
      "  -1.32107150e-01  1.05478388e+00  7.92587472e-01  2.67910787e+00\n",
      "   1.17421078e+00  4.93967629e-01 -2.14250485e-01 -7.27982907e-01\n",
      "  -1.68395025e+00  5.28196939e-01  1.69350802e+00  6.38496704e-02]\n",
      " [ 3.14207777e-01  2.41738919e-01  1.84507200e+00  1.49176642e+00\n",
      "   1.65359664e+00 -2.95644502e-01  2.94602588e+00 -4.96977141e-01\n",
      "  -2.46059764e-01 -2.05550925e-01 -7.49733240e-01  1.15915220e-01\n",
      "  -1.65401760e-01 -1.12562682e+00 -9.23047579e-01 -5.72514117e-01]\n",
      " [ 3.49859839e+00 -2.82758209e-01 -2.44137815e+00  2.44867094e+00\n",
      "  -1.19166303e+00 -5.36780799e-01  8.18598648e-01  2.53296232e+00\n",
      "   7.83380365e-01 -2.56598693e+00  1.50658886e+00 -2.41636308e-01\n",
      "   8.73926111e-01 -1.76286864e+00  4.68128931e-01 -6.19438585e-01]\n",
      " [-2.25449916e+00  4.89757145e-02 -7.87251686e-01 -2.50217839e+00\n",
      "  -8.48880836e-01  4.23402439e-02 -3.04846267e-01 -7.90183797e-02\n",
      "   5.40443515e-01  1.59139013e+00  1.51677895e+00 -1.89286838e+00\n",
      "  -2.10947730e-01  1.45331907e+00 -1.04361267e+00  8.62784146e-01]\n",
      " [-1.57852903e+00  2.77139141e+00 -3.41041798e-01 -8.35406440e-01\n",
      "   2.05087734e+00  5.62032643e-01  9.94856303e-01  2.14228416e-01\n",
      "  -5.10105054e-01 -1.55587015e+00  4.29854096e+00  1.19969147e+00\n",
      "  -1.85972542e+00  1.28802968e-01 -1.66793656e+00  7.43897775e-01]]\n",
      "\n",
      "Forward pass with activation levels:\n",
      "Activation levels of hidden nodes (before bias):\n",
      "[8.12268212e-02 1.57715347e-01 7.29909719e-01 1.00687641e-01\n",
      " 1.70547956e-04 8.31925275e-04 1.93245610e-05 6.67022237e-04\n",
      " 7.80146036e-04 1.26868708e-03 1.07579261e-01 1.29669763e-06\n",
      " 1.83423614e-01 9.20327198e-01 9.50069942e-01]\n",
      "\n",
      "Activation levels of output nodes:\n",
      "[0.66963713 0.76001074 0.35276628 0.29234849 0.1701547  0.81969818\n",
      " 0.26182244 0.05884716 0.58263424 0.34831251]\n"
     ]
    }
   ],
   "source": [
    "# preparato da Copilot via WhatsApp\n",
    "import numpy as np\n",
    "\n",
    "# Sigmoid activation function and its derivative\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# ANN parameters\n",
    "input_nodes = 10\n",
    "hidden_nodes = 15\n",
    "output_nodes = 10\n",
    "learning_rate = 0.1\n",
    "epochs = 1000\n",
    "\n",
    "# Initialize weights randomly\n",
    "weights_input_hidden = np.random.rand(hidden_nodes, input_nodes + 1) - 0.5  # +1 for bias\n",
    "weights_hidden_output = np.random.rand(output_nodes, hidden_nodes + 1) - 0.5  # +1 for bias\n",
    "\n",
    "# Training phase\n",
    "def train(inputs, expected_output):\n",
    "    global weights_input_hidden, weights_hidden_output\n",
    "    \n",
    "    inputs_with_bias = np.append(inputs, 1)  # Add bias to inputs\n",
    "    hidden_inputs = np.dot(weights_input_hidden, inputs_with_bias)\n",
    "    hidden_outputs = sigmoid(hidden_inputs)\n",
    "    \n",
    "    hidden_outputs_with_bias = np.append(hidden_outputs, 1)  # Add bias to hidden outputs\n",
    "    final_inputs = np.dot(weights_hidden_output, hidden_outputs_with_bias)\n",
    "    final_outputs = sigmoid(final_inputs)\n",
    "    \n",
    "    # Error calculation\n",
    "    output_error = expected_output - final_outputs\n",
    "    hidden_error = np.dot(weights_hidden_output[:, :-1].T, output_error) * sigmoid_derivative(hidden_outputs)\n",
    "\n",
    "    # Update weights\n",
    "    weights_hidden_output += learning_rate * np.outer(output_error * sigmoid_derivative(final_outputs), hidden_outputs_with_bias)\n",
    "    weights_input_hidden += learning_rate * np.outer(hidden_error, inputs_with_bias)\n",
    "\n",
    "# Forward application phase with activations display\n",
    "def forward_pass_with_activations(inputs):\n",
    "    inputs_with_bias = np.append(inputs, 1)  # Add bias to inputs\n",
    "    hidden_inputs = np.dot(weights_input_hidden, inputs_with_bias)\n",
    "    hidden_outputs = sigmoid(hidden_inputs)\n",
    "    \n",
    "    print(\"Activation levels of hidden nodes (before bias):\")\n",
    "    print(hidden_outputs)\n",
    "    \n",
    "    hidden_outputs_with_bias = np.append(hidden_outputs, 1)  # Add bias to hidden outputs\n",
    "    final_inputs = np.dot(weights_hidden_output, hidden_outputs_with_bias)\n",
    "    final_outputs = sigmoid(final_inputs)\n",
    "    \n",
    "    print(\"\\nActivation levels of output nodes:\")\n",
    "    print(final_outputs)\n",
    "    \n",
    "    return final_outputs\n",
    "\n",
    "# Generate example data\n",
    "np.random.seed(42)\n",
    "training_inputs = np.random.rand(100, input_nodes)  # 100 samples, 10 input nodes\n",
    "training_outputs = np.random.rand(100, output_nodes)  # 100 samples, 10 output nodes\n",
    "\n",
    "# Train the network\n",
    "for epoch in range(epochs):\n",
    "    for i in range(len(training_inputs)):\n",
    "        train(training_inputs[i], training_outputs[i])\n",
    "\n",
    "# Display final weight matrices\n",
    "print(\"Weights from input to hidden layer after learning:\")\n",
    "print(weights_input_hidden)\n",
    "print(\"\\nWeights from hidden to output layer after learning:\")\n",
    "print(weights_hidden_output)\n",
    "\n",
    "# Test the network with new inputs and display activations\n",
    "test_inputs = np.random.rand(input_nodes)\n",
    "print(\"\\nForward pass with activation levels:\")\n",
    "test_outputs = forward_pass_with_activations(test_inputs)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f1c0e502-17f4-434d-9488-721712a6f148",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "1.⁠ ⁠Activation Levels :\n",
    "   - During the forward pass, the activation levels (outputs after the sigmoid function) \n",
    "     of all hidden and output nodes are displayed.\n",
    "2.⁠ ⁠Training :\n",
    "   - The network trains for the specified epochs using backpropagation, updating the weights.\n",
    "3.⁠ ⁠Final Weights :\n",
    "   - After training, the updated weights for both layers are printed.\n",
    "4.⁠ ⁠Test with Activations :\n",
    "   - A random test input is passed through the network, and the activation levels of each node \n",
    "     in the hidden and output layers are shown step by step.\n",
    "\n",
    "This approach allows you to not only use the ANN for predictions but also observe the internal \n",
    "activations, which can be valuable for understanding the model's behavior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
