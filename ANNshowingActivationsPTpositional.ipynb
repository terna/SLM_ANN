{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "870357f0-b9f5-4c0a-97d9-72dfdebaeefe",
   "metadata": {},
   "source": [
    "# 0  \n",
    "\n",
    "#### Che cosa è SLM_ANN  \n",
    "Una rete neurale artificiale che opera \"come se\" fosse un piccolo modello linguistico, quindi Small Language Model, **SLM**  \n",
    "#### Come si usa\n",
    "\n",
    "Con clic su ![](https://terna.to.it/SLM_ANN/binder.png), attendendo qualche minuto, il programma diviene funzionante su un computer remoto. Con clic su ![](https://terna.to.it/SLM_ANN/esecuzione.png) il progamma va in esecuzione.  \n",
    "\n",
    "#### Che prove si possono fare  \n",
    "\n",
    "Nella casella **3**, se si sostituisce *False* con *True* e si fa clic su ![](https://terna.to.it/SLM_ANN/esecuzioneSpecifica.png) si ottiene il voluminoso output dei parametri del modello.  \n",
    "\n",
    "Nella casella **5** si possono sostituire i termini in input, prima di tutto seguendo le frasi riportate qui sotto e poi provando a disporre in modo capriccioso le parole e gli spazi. Per eseguire la sola cella 5, in cui si sta lavorando, fare clic su ![](https://terna.to.it/SLM_ANN/esecuzioneSpecifica.png)\n",
    "\n",
    "Se si usa un termine non compreso nelle frasi riportate, la parola errata è riportata e l'esecuzione si arresta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b244c46-17bb-4614-88f2-95d460fd9d4a",
   "metadata": {},
   "source": [
    "  \n",
    "-----------------------------    \n",
    "casistica, con **>** che separa l'input dall'output.\n",
    "\n",
    "\n",
    "il,gatto,mangia,>,il,topo  \n",
    "il,gatto, ,>,miagola,  \n",
    "il,cane,mangia,>,il,gatto  \n",
    "il,cane, ,>,abbaia,  \n",
    "il,topo,mangia,>,il,formaggio  \n",
    "il,bimbo,chiama,>,la,mamma  \n",
    "il,bimbo,mangia,>,la,pappa  \n",
    "il,bimbo, ,>,piange,  \n",
    "bimbo,e,gatto,>,giocano,  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19529748-8138-4573-ae8d-f2fe5d36ab7e",
   "metadata": {},
   "source": [
    "# 1\n",
    "#### dizionari di servizio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c488cb47-c078-499f-be4a-b0f5909d9a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = \\\n",
    " {' ': 0, 'il': 1, 'gatto': 2, 'mangia': 3, 'topo': 4, 'miagola': 5, 'cane': 6, 'abbaia': 7, 'formaggio': 8, 'bimbo': 9, \n",
    "  'chiama': 10, 'la': 11, 'mamma': 12, 'pappa': 13, 'piange': 14, 'e': 15, 'giocano': 16}\n",
    "reverseDictionary= \\\n",
    "{0: ' ', 1: 'il', 2: 'gatto', 3: 'mangia', 4: 'topo', 5: 'miagola', 6: 'cane', 7: 'abbaia', 8: 'formaggio', 9: 'bimbo', \n",
    " 10: 'chiama', 11: 'la', 12: 'mamma', 13: 'pappa', 14: 'piange', 15: 'e', 16: 'giocano'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10700462-0ace-406d-b9fa-28dea4fe8d77",
   "metadata": {},
   "source": [
    "# 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89b8c3aa-13f1-4a96-a52e-96ec9ad4d436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparato da Copilot via WhatsApp\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Sigmoid activation function and its derivative\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# ANN parameters\n",
    "input_nodes = 17*3\n",
    "hidden_nodes = 100\n",
    "output_nodes = 17*2\n",
    "learning_rate = 0.5\n",
    "epochs = 10000\n",
    "\n",
    "# Initialize weights randomly\n",
    "np.random.seed(42)\n",
    "weights_input_hidden = np.random.rand(hidden_nodes, input_nodes + 1) - 0.5  # +1 for bias\n",
    "weights_hidden_output = np.random.rand(output_nodes, hidden_nodes + 1) - 0.5  # +1 for bias\n",
    "\n",
    "# Training phase\n",
    "def train(inputs, expected_output):\n",
    "    global weights_input_hidden, weights_hidden_output\n",
    "    \n",
    "    inputs_with_bias = np.append(inputs, 1)  # Add bias to inputs\n",
    "    hidden_inputs = np.dot(weights_input_hidden, inputs_with_bias)\n",
    "    hidden_outputs = sigmoid(hidden_inputs)\n",
    "    \n",
    "    hidden_outputs_with_bias = np.append(hidden_outputs, 1)  # Add bias to hidden outputs\n",
    "    final_inputs = np.dot(weights_hidden_output, hidden_outputs_with_bias)\n",
    "    final_outputs = sigmoid(final_inputs)\n",
    "    \n",
    "    # Error calculation\n",
    "    output_error = expected_output - final_outputs\n",
    "    hidden_error = np.dot(weights_hidden_output[:, :-1].T, output_error) * sigmoid_derivative(hidden_outputs)\n",
    "\n",
    "    # Update weights\n",
    "    weights_hidden_output += learning_rate * np.outer(output_error * sigmoid_derivative(final_outputs), hidden_outputs_with_bias)\n",
    "    weights_input_hidden += learning_rate * np.outer(hidden_error, inputs_with_bias)\n",
    "\n",
    "# Forward application phase with activations display\n",
    "def forward_pass_with_activations(inputs):\n",
    "    inputs_with_bias = np.append(inputs, 1)  # Add bias to inputs\n",
    "    hidden_inputs = np.dot(weights_input_hidden, inputs_with_bias)\n",
    "    hidden_outputs = sigmoid(hidden_inputs)\n",
    "    \n",
    "    print(\"Activation levels of hidden nodes (before bias):\")\n",
    "    print(hidden_outputs)\n",
    "    \n",
    "    hidden_outputs_with_bias = np.append(hidden_outputs, 1)  # Add bias to hidden outputs\n",
    "    final_inputs = np.dot(weights_hidden_output, hidden_outputs_with_bias)\n",
    "    final_outputs = sigmoid(final_inputs)\n",
    "    \n",
    "    print(\"\\nActivation levels of output nodes:\")\n",
    "    print(final_outputs[0:17])\n",
    "    print(final_outputs[17:])\n",
    "    \n",
    "    return final_outputs\n",
    "\n",
    "# Example data\n",
    "training_inputs =[]\n",
    "with open(\"in.txt\", 'r') as file1:\n",
    "    for line in file1:\n",
    "        # Remove leading/trailing whitespace and brackets\n",
    "        line = line.strip().strip('[]')\n",
    "        # Split the line into individual numbers and convert to integers\n",
    "        numbers = [float(num.strip()) for num in line.split(',')]\n",
    "        training_inputs.append(numbers)\n",
    "#print(training_inputs)\n",
    "\n",
    "training_outputs =[]\n",
    "with open(\"ou.txt\", 'r') as file2:\n",
    "    for line in file2:\n",
    "        # Remove leading/trailing whitespace and brackets\n",
    "        line = line.strip().strip('[]')\n",
    "        # Split the line into individual numbers and convert to integers\n",
    "        numbers = [float(num.strip()) for num in line.split(',')]\n",
    "        training_outputs.append(numbers)\n",
    "#print(training_outputs)\n",
    "\n",
    "# Train the network\n",
    "for epoch in range(epochs):\n",
    "    for i in range(len(training_inputs)):\n",
    "        train(training_inputs[i], training_outputs[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a7789d-6e69-4d0c-b639-05782fdf869c",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a5d2fb6-63df-4aca-91dd-d2926677b4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to show the weights change to True and run\n",
    "show=False\n",
    "\n",
    "\n",
    "if show:\n",
    "    # Display final weight matrices\n",
    "    print(\"Weights from input to hidden layer after learning:\")\n",
    "    for i in range(len(weights_input_hidden)):\n",
    "        print(weights_input_hidden[i])\n",
    "    print(\"\\nWeights from hidden to output layer after learning:\")\n",
    "    for i in range(len(weights_hidden_output)):\n",
    "        print(weights_hidden_output[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e148a6-acc3-47c0-8049-503173029ec5",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dfd02de-4d11-4b8d-8aac-edae31f75204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inOutExperiments(i0,i1,i2):\n",
    "    inExp=[0]*17*3\n",
    "    try: inExp[dictionary[i0]]=1\n",
    "    except: \n",
    "        print(i0, \" parola sconosciuta\")\n",
    "        return\n",
    "    try: inExp[dictionary[i1]+17]=1\n",
    "    except: \n",
    "        print(i1, \" parola sconosciuta\")\n",
    "        return\n",
    "    try: inExp[dictionary[i2]+17*2]=1\n",
    "    except: \n",
    "        print(i2, \" parola sconosciuta\")\n",
    "        return\n",
    "    print(inExp)\n",
    "\n",
    "    test_outputs = forward_pass_with_activations([inExp])\n",
    "    phrase = f\"{reverseDictionary[np.argmax(test_outputs[0:17])]} {reverseDictionary[np.argmax(test_outputs[17:])]}\" \n",
    "    print()\n",
    "    print(phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8075e5c-4cc9-4064-9365-8a2b9905a79a",
   "metadata": {},
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb15ec30-fbbe-4c97-af15-e953d829cb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Activation levels of hidden nodes (before bias):\n",
      "[8.52667076e-04 3.76233665e-01 1.24085802e-02 5.87899203e-02\n",
      " 5.25646680e-01 2.96539832e-01 8.26595051e-02 4.66670418e-01\n",
      " 5.89544915e-02 3.89304742e-02 2.00868666e-01 3.39681154e-02\n",
      " 7.99096794e-02 3.08726649e-02 1.55669536e-02 1.55864669e-01\n",
      " 2.05911907e-02 4.37397178e-04 1.48945843e-01 1.09761162e-01\n",
      " 2.04311357e-01 6.95854356e-02 1.31973226e-01 4.80157997e-02\n",
      " 8.78708356e-03 4.52705774e-03 1.16020346e-01 2.12630927e-01\n",
      " 9.78817058e-02 2.21690021e-01 9.85294318e-03 2.61604208e-02\n",
      " 2.17035856e-01 1.69050231e-01 2.64147163e-02 6.01983373e-02\n",
      " 8.26953735e-01 6.45460366e-01 3.16375369e-01 3.13963836e-02\n",
      " 3.33486416e-02 1.21427673e-02 1.09238395e-02 7.71831005e-01\n",
      " 9.24674411e-02 1.54311272e-03 5.18088241e-02 8.09757672e-02\n",
      " 2.10804565e-01 1.16544618e-01 6.46867351e-02 1.54831455e-01\n",
      " 1.51061577e-01 3.69085494e-02 7.71253730e-03 8.23625269e-01\n",
      " 2.32392852e-01 2.15330698e-02 3.00211069e-02 2.01913759e-03\n",
      " 8.78045929e-03 9.10433690e-01 1.50477470e-01 8.01611895e-02\n",
      " 2.09181854e-01 1.14182074e-01 9.38388023e-01 7.60801199e-01\n",
      " 5.77716624e-01 4.96391416e-01 2.47102255e-02 4.56560630e-02\n",
      " 7.34341058e-02 5.48267178e-02 1.21254723e-02 1.77499369e-01\n",
      " 4.13116780e-02 1.33418859e-02 6.25585488e-02 4.89810464e-02\n",
      " 8.66177054e-01 2.13298276e-01 4.57153950e-02 9.01717680e-01\n",
      " 1.68589942e-01 1.43013292e-02 3.62653941e-01 2.58360510e-02\n",
      " 7.88651081e-01 1.14493636e-02 6.17774877e-01 7.42628092e-02\n",
      " 1.98102938e-01 3.76156397e-01 6.88643284e-02 2.56623772e-01\n",
      " 1.69071339e-02 8.21198776e-02 9.39244847e-01 3.19298448e-01]\n",
      "\n",
      "Activation levels of output nodes:\n",
      "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.9 0.1 0.1 0.1 0.1 0.1]\n",
      "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.9 0.1 0.1 0.1]\n",
      "\n",
      "la pappa\n"
     ]
    }
   ],
   "source": [
    "inOutExperiments(\"il\",\"bimbo\",\"mangia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403f60a8-a798-431e-b621-2c25526972b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
