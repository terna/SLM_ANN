{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "870357f0-b9f5-4c0a-97d9-72dfdebaeefe",
   "metadata": {},
   "source": [
    "# 0  \n",
    "\n",
    "#### Che cosa è SLM_ANN  \n",
    "Una rete neurale artificiale che opera \"come se\" fosse un piccolo modello linguistico, quindi Small Language Model, **SLM**  \n",
    "#### Come si usa\n",
    "\n",
    "Con clic su ![](https://terna.to.it/SLM_ANN/binder.png), attendendo qualche minuto, il programma diviene funzionante su un computer remoto. Con clic su ![](https://terna.to.it/SLM_ANN/esecuzione.png) il progamma va in esecuzione.  \n",
    "\n",
    "#### Che prove si possono fare  \n",
    "\n",
    "Nella casella **3**, se si sostituisce *False* con *True* e si fa clic su ![](https://terna.to.it/SLM_ANN/esecuzioneSpecifica.png) si ottiene il voluminoso output dei parametri del modello.  \n",
    "\n",
    "Nella casella **5** si possono sostituire i termini in input, prima di tutto seguendo le frasi riportate qui sotto e poi provando a disporre in modo capriccioso le parole e gli spazi. Per eseguire la sola cella 5, in cui si sta lavorando, fare clic su ![](https://terna.to.it/SLM_ANN/esecuzioneSpecifica.png)\n",
    "\n",
    "Se si usa un termine non compreso nelle frasi riportate, la parola errata è riportata e l'esecuzione si arresta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b244c46-17bb-4614-88f2-95d460fd9d4a",
   "metadata": {},
   "source": [
    "  \n",
    "-----------------------------    \n",
    "casistica, con **>** che separa l'input dall'output.\n",
    "\n",
    "\n",
    "il,gatto,mangia,>,il,topo  \n",
    "il,gatto, ,>,miagola,  \n",
    "il,cane,mangia,>,il,gatto  \n",
    "il,cane, ,>,abbaia,  \n",
    "il,topo,mangia,>,il,formaggio  \n",
    "il,bimbo,chiama,>,la,mamma  \n",
    "il,bimbo,mangia,>,la,pappa  \n",
    "il,bimbo, ,>,piange,  \n",
    "bimbo,e,gatto,>,giocano,  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19529748-8138-4573-ae8d-f2fe5d36ab7e",
   "metadata": {},
   "source": [
    "# 1\n",
    "#### dizionari di servizio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c488cb47-c078-499f-be4a-b0f5909d9a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = \\\n",
    " {' ': 0, 'il': 1, 'gatto': 2, 'mangia': 3, 'topo': 4, 'miagola': 5, 'cane': 6, 'abbaia': 7, 'formaggio': 8, 'bimbo': 9, \n",
    "  'chiama': 10, 'la': 11, 'mamma': 12, 'pappa': 13, 'piange': 14, 'e': 15, 'giocano': 16}\n",
    "reverseDictionary= \\\n",
    "{0: ' ', 1: 'il', 2: 'gatto', 3: 'mangia', 4: 'topo', 5: 'miagola', 6: 'cane', 7: 'abbaia', 8: 'formaggio', 9: 'bimbo', \n",
    " 10: 'chiama', 11: 'la', 12: 'mamma', 13: 'pappa', 14: 'piange', 15: 'e', 16: 'giocano'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10700462-0ace-406d-b9fa-28dea4fe8d77",
   "metadata": {},
   "source": [
    "# 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89b8c3aa-13f1-4a96-a52e-96ec9ad4d436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparato da Copilot via WhatsApp\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Sigmoid activation function and its derivative\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# ANN parameters\n",
    "input_nodes = 17*3\n",
    "hidden_nodes = 100\n",
    "output_nodes = 17*2\n",
    "learning_rate = 0.5\n",
    "epochs = 10000\n",
    "\n",
    "# Initialize weights randomly\n",
    "np.random.seed(42)\n",
    "weights_input_hidden = np.random.rand(hidden_nodes, input_nodes + 1) - 0.5  # +1 for bias\n",
    "weights_hidden_output = np.random.rand(output_nodes, hidden_nodes + 1) - 0.5  # +1 for bias\n",
    "\n",
    "# Training phase\n",
    "def train(inputs, expected_output):\n",
    "    global weights_input_hidden, weights_hidden_output\n",
    "    \n",
    "    inputs_with_bias = np.append(inputs, 1)  # Add bias to inputs\n",
    "    hidden_inputs = np.dot(weights_input_hidden, inputs_with_bias)\n",
    "    hidden_outputs = sigmoid(hidden_inputs)\n",
    "    \n",
    "    hidden_outputs_with_bias = np.append(hidden_outputs, 1)  # Add bias to hidden outputs\n",
    "    final_inputs = np.dot(weights_hidden_output, hidden_outputs_with_bias)\n",
    "    final_outputs = sigmoid(final_inputs)\n",
    "    \n",
    "    # Error calculation\n",
    "    output_error = expected_output - final_outputs\n",
    "    hidden_error = np.dot(weights_hidden_output[:, :-1].T, output_error) * sigmoid_derivative(hidden_outputs)\n",
    "\n",
    "    # Update weights\n",
    "    weights_hidden_output += learning_rate * np.outer(output_error * sigmoid_derivative(final_outputs), hidden_outputs_with_bias)\n",
    "    weights_input_hidden += learning_rate * np.outer(hidden_error, inputs_with_bias)\n",
    "\n",
    "# Forward application phase with activations display\n",
    "def forward_pass_with_activations(inputs):\n",
    "    inputs_with_bias = np.append(inputs, 1)  # Add bias to inputs\n",
    "    hidden_inputs = np.dot(weights_input_hidden, inputs_with_bias)\n",
    "    hidden_outputs = sigmoid(hidden_inputs)\n",
    "    \n",
    "    print(\"Activation levels of hidden nodes (before bias):\")\n",
    "    print(hidden_outputs)\n",
    "    \n",
    "    hidden_outputs_with_bias = np.append(hidden_outputs, 1)  # Add bias to hidden outputs\n",
    "    final_inputs = np.dot(weights_hidden_output, hidden_outputs_with_bias)\n",
    "    final_outputs = sigmoid(final_inputs)\n",
    "    \n",
    "    print(\"\\nActivation levels of output nodes:\")\n",
    "    print(final_outputs[0:17])\n",
    "    print(final_outputs[17:])\n",
    "    \n",
    "    return final_outputs\n",
    "\n",
    "# Example data\n",
    "training_inputs =[]\n",
    "with open(\"in.txt\", 'r') as file1:\n",
    "    for line in file1:\n",
    "        # Remove leading/trailing whitespace and brackets\n",
    "        line = line.strip().strip('[]')\n",
    "        # Split the line into individual numbers and convert to integers\n",
    "        numbers = [float(num.strip()) for num in line.split(',')]\n",
    "        training_inputs.append(numbers)\n",
    "#print(training_inputs)\n",
    "\n",
    "training_outputs =[]\n",
    "with open(\"ou.txt\", 'r') as file2:\n",
    "    for line in file2:\n",
    "        # Remove leading/trailing whitespace and brackets\n",
    "        line = line.strip().strip('[]')\n",
    "        # Split the line into individual numbers and convert to integers\n",
    "        numbers = [float(num.strip()) for num in line.split(',')]\n",
    "        training_outputs.append(numbers)\n",
    "#print(training_outputs)\n",
    "\n",
    "# Train the network\n",
    "for epoch in range(epochs):\n",
    "    for i in range(len(training_inputs)):\n",
    "        train(training_inputs[i], training_outputs[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a7789d-6e69-4d0c-b639-05782fdf869c",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a5d2fb6-63df-4aca-91dd-d2926677b4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to show the weights change to True and run\n",
    "show=False\n",
    "\n",
    "\n",
    "if show:\n",
    "    # Display final weight matrices\n",
    "    print(\"Weights from input to hidden layer after learning:\")\n",
    "    for i in range(len(weights_input_hidden)):\n",
    "        print(weights_input_hidden[i])\n",
    "    print(\"\\nWeights from hidden to output layer after learning:\")\n",
    "    for i in range(len(weights_hidden_output)):\n",
    "        print(weights_hidden_output[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e148a6-acc3-47c0-8049-503173029ec5",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dfd02de-4d11-4b8d-8aac-edae31f75204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inOutExperiments(i0,i1,i2):\n",
    "    inExp=[0]*17*3\n",
    "    try: inExp[dictionary[i0]]=1\n",
    "    except: \n",
    "        print(i0, \" parola sconosciuta\")\n",
    "        return\n",
    "    try: inExp[dictionary[i1]+17]=1\n",
    "    except: \n",
    "        print(i1, \" parola sconosciuta\")\n",
    "        return\n",
    "    try: inExp[dictionary[i2]+17*2]=1\n",
    "    except: \n",
    "        print(i2, \" parola sconosciuta\")\n",
    "        return\n",
    "    print(inExp)\n",
    "\n",
    "    test_outputs = forward_pass_with_activations([inExp])\n",
    "    phrase = f\"{reverseDictionary[np.argmax(test_outputs[0:17])]} {reverseDictionary[np.argmax(test_outputs[17:])]}\" \n",
    "    print()\n",
    "    print(phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8075e5c-4cc9-4064-9365-8a2b9905a79a",
   "metadata": {},
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb15ec30-fbbe-4c97-af15-e953d829cb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "Activation levels of hidden nodes (before bias):\n",
      "[0.01230582 0.31826467 0.01563554 0.07641462 0.32209056 0.37079778\n",
      " 0.12479367 0.13667516 0.06551611 0.13695286 0.40114516 0.01749173\n",
      " 0.01869754 0.03540727 0.02602721 0.23417531 0.01211937 0.00616674\n",
      " 0.33782679 0.10072568 0.11024196 0.25056714 0.17737199 0.33420271\n",
      " 0.08372004 0.03023555 0.05767628 0.35512394 0.16312645 0.18055432\n",
      " 0.04079688 0.13554722 0.12348037 0.38580526 0.00360127 0.39435178\n",
      " 0.75842061 0.24526343 0.29673963 0.08087801 0.06252613 0.04177483\n",
      " 0.03128719 0.61123042 0.12069992 0.01422157 0.05291792 0.05848373\n",
      " 0.45605485 0.12282076 0.04186474 0.08961387 0.19890572 0.09176095\n",
      " 0.03475234 0.38357465 0.27284482 0.00280961 0.07854578 0.00670983\n",
      " 0.02496732 0.65996206 0.36279212 0.05470974 0.10620242 0.07746619\n",
      " 0.96483345 0.49732469 0.42030276 0.25473109 0.07989503 0.02134908\n",
      " 0.20099478 0.149396   0.01692567 0.1691954  0.01481461 0.02158254\n",
      " 0.1142116  0.08249465 0.79343668 0.12053222 0.11894418 0.39783981\n",
      " 0.18423144 0.03668369 0.61444802 0.07164636 0.8471748  0.022324\n",
      " 0.42274235 0.11713585 0.16330261 0.19697968 0.38575693 0.13451902\n",
      " 0.08999113 0.05025675 0.87733268 0.11179844]\n",
      "\n",
      "Activation levels of output nodes:\n",
      "[0.08347224 0.088216   0.08087947 0.07986851 0.07656088 0.06952745\n",
      " 0.10334838 0.08831357 0.0884515  0.11387144 0.10059574 0.61753553\n",
      " 0.10678968 0.11044406 0.42445296 0.09470956 0.09863056]\n",
      "[0.32175218 0.07925686 0.07607679 0.09764535 0.09216063 0.13072047\n",
      " 0.09522394 0.10191919 0.10318465 0.08877207 0.08418953 0.11298929\n",
      " 0.31371334 0.35365102 0.10578829 0.09054057 0.08729789]\n",
      "\n",
      "la pappa\n"
     ]
    }
   ],
   "source": [
    "inOutExperiments(\"il\",\"bimbo\",\"la\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403f60a8-a798-431e-b621-2c25526972b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
